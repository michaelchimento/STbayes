title = "Estimated Acquisition Times with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_point(size = 2) +
geom_crossbar(aes(ymin = lower_hpd, ymax = upper_hpd), size=1) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated Acquisition Times with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_point(size = 2) +
geom_errorbar(aes(ymin = lower_hpd, ymax = upper_hpd), size=1) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated Acquisition Times with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=1) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated Acquisition Times with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated Acquisition Times with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated Acquisition Times with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_abline(slope = 1, intercept = 0,             # Line y = x
color = "red", linetype = "dotted", size = 1) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
# fit model
fit = fit_STb(data_list_user, "../data/model_from_simulate_data.stan", chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99))
# fit model
fit = fit_STb(data_list_user, "../data/model_from_simulate_data.stan", chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99))
unloadNamespace("STbayes")
devtools::document()
devtools::install()
library(STbayes)
library(igraph)
library(dplyr)
library(NBDA)
library(ggplot2)
# Parameters
N <- 50  # Population size
k <- 4    # Degree of each node in the random regular graph
lambda_0=0.001 #baseline
A <- 1  # Individual learning rate
s <- 5  # Social learning rate per unit connection
t_steps <- 1000
max_time = t_steps+1
# create random regular graph
g <- sample_k_regular(N, k, directed = FALSE, multiple = FALSE)
V(g)$name <- 1:N
# initialize a dataframe to store the time of acquisition data
df <- data.frame(id=1:N, time=max_time, max_time = max_time)
# simulate the diffusion
for (t in 1:t_steps) {
# identify knowledgeable individuals
informed <- df[df$time < max_time, "id"]
# identify naive
potential_learners <- c(1:N)
potential_learners <- potential_learners[!(potential_learners %in% informed)]
# break the loop if no one left to learn,
if (length(potential_learners) == 0) break
# calc the hazard
learning_rates <- sapply(potential_learners, function(x) {
neighbors <- neighbors(g, x)
C <- sum(neighbors$name %in% informed)
lambda <- lambda_0 * (A + s*C)
return(lambda)
})
# convert hazard to probability
learning_probs <- 1 - exp(-learning_rates)
# for each potential learner, determine whether they learn the behavior
learners_this_step <- rbinom(n=length(potential_learners), size=1, prob=learning_probs)
# update their time of acquisition
new_learners <- potential_learners[learners_this_step == 1]
df[df$id %in% new_learners, "time"] <- t
}
diffusion_data <- df %>%
arrange(time) %>%
group_by(time, .drop = T) %>%
mutate(tie=ifelse(n()>1,1,0),
seed=ifelse(time==0,1,0))
hist(diffusion_data$time)
# Define the adjacency matrix
adj_matrix <- as_adjacency_matrix(g, attr=NULL, sparse=FALSE)
dim(adj_matrix) = c(N,N,1)
tie_vec = diffusion_data %>% arrange(time) %>% ungroup() %>% select(tie)
seed_vec = diffusion_data %>% arrange(id) %>% ungroup() %>% select(seed)
#### Fit NBDA model ####
d = nbdaData(label="sim_data",
assMatrix = adj_matrix,
orderAcq = diffusion_data$id,
timeAcq = diffusion_data$time,
endTime = max_time,
ties = tie_vec$tie,
demons = seed_vec$seed)
result = tadaFit(d)
data.frame(Variable=result@varNames,MLE=result@outputPar,SE=result@se)
est_rate = 1/result@outputPar[1]
est_rate
#import into STbayes
diffusion_data <- diffusion_data %>%
mutate(trial=1) %>%
select(-c(tie, seed))
edge_list <- as.data.frame(as_edgelist(g))
names(edge_list) = c("from","to")
edge_list$trial = 1
edge_list$assoc = 1 #assign named edgeweight since this is just an edge list
#generate STAN model from input data
data_list_user = import_user_STb(diffusion_data, edge_list)
#generate STAN model from input data
model_obj = generate_STb_model(data_list_user, gq=TRUE, est_acqTime = T)
# suggest writing to file for debugging
write(model_obj, file = "../data/model_from_simulate_data.stan")
# fit model
fit = fit_STb(data_list_user, "../data/model_from_simulate_data.stan", chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99))
#'   diffusion_data = diffusion_data,
#'   networks = networks,
#'   ILV_metadata = ILV_metadata,
#'   ILVi = c("age"), # Use only 'age' for asocial learning
#'   ILVs = c("sex") # Use only 'sex' for social learning
#' )
#'
#' model = generate_STb_model(data_list)
#' model = generate_STb_model(data_list, N_veff=2) # estimate varying effects for s and lambda_0.
#' print(model)
generate_STb_model <- function(STb_data, N_veff = 0, gq = TRUE, est_acqTime = FALSE) {
network_names = STb_data$network_names
ILVi_vars = STb_data$ILVi_names[!STb_data$ILVi_names %in% "ILVabsent"]
ILVs_vars = STb_data$ILVs_names[!STb_data$ILVs_names %in% "ILVabsent"]
ILVm_vars = STb_data$ILVm_names[!STb_data$ILVm_names %in% "ILVabsent"]
combined_ILV_vars = unique(c(ILVi_vars, ILVs_vars, ILVm_vars))
ILV_declaration = ""
if (length(combined_ILV_vars)>0){
ILV_declaration = paste0('array[Z] real ', combined_ILV_vars, ';', collapse = '\\n')
}
# Placeholders for dynamic components
num_networks <- length(STb_data$network_names)
num_ILVi = length(ILVi_vars)
num_ILVs = length(ILVs_vars)
num_ILVm = length(ILVm_vars)
if (num_networks == 1) {
network_term <- paste0("sum(A_", network_names[1], "[trial, time_step][id, ] .* C[trial][time_step, ])")
w_param <- ""
w_prior <- ""
} else {
network_term <- paste0("w[", 1:num_networks, "] * sum(A_", network_names, "[trial, time_step][id, ] .* C[trial][time_step, ])", collapse = " + ")
w_param <- paste0("simplex[", num_networks, "] w; // Weights for networks")
w_prior <- paste0("w ~ dirichlet(rep_vector(0.5, ", num_networks, "));")
}
# Handle individual-level information (ILVi)
if (num_ILVi < 1) {
ILVi_param <- ""
ILVi_prior <- ""
ILVi_variable_effects <- "1"
} else {
ILVi_param <- paste0("real beta_ILVi_", ILVi_vars, ";", sep = "\n")
ILVi_prior <- paste0("beta_ILVi_", ILVi_vars, " ~ normal(0, 1);", sep = "\n")
ILVi_variable_effects <- paste0("exp(", paste0("beta_ILVi_", ILVi_vars, " * ", ILVi_vars, "[id]", collapse = " + "),")")
}
# Handle social-level information (ILVs)
if (num_ILVs < 1) {
ILVs_param <- ""
ILVs_prior <- ""
ILVs_variable_effects <- ""
} else {
ILVs_param <- paste0("real beta_ILVs_", ILVs_vars, ";", sep = "\n")
ILVs_prior <- paste0("beta_ILVs_", ILVs_vars, " ~ normal(0, 1);", sep = "\n")
ILVs_variable_effects <- paste0("* exp(", paste0("beta_ILVs_", ILVs_vars, " * ", ILVs_vars, "[id]", collapse = " + "),")")
}
# Handle social-level information (ILVs)
if (num_ILVm < 1) {
ILVm_param <- ""
ILVm_prior <- ""
ILVm_variable_effects <- ""
} else {
ILVm_param <- paste0("real beta_ILVm_", ILVm_vars, ";", sep = "\n")
ILVm_prior <- paste0("beta_ILVm_", ILVm_vars, " ~ normal(0, 1);", sep = "\n")
ILVm_variable_effects <- paste0("exp(", paste0("beta_ILVm_", ILVm_vars, " * ", ILVm_vars, "[id] *", collapse = " + "),")")
}
data_block <- glue::glue("
data {{
int<lower=0> K;                // Number of trials
int<lower=0> Q;                // Number of individuals in each trial
int<lower=1> Z;                // Number of unique individuals
array[K] int<lower=1> N;       // Number of individuals that learned during observation period
array[K] int<lower=0> N_c;     // Number of right-censored individuals
array[K, Q] int<lower=1> ind_id; // IDs of individuals
array[K] int<lower=1> T;       // Maximum time periods
int<lower=1> T_max;            // Max timesteps reached
{if (est_acqTime) 'array[K] int<lower=0> time_max; //Duration of obs period for each trial' else ''}
array[K,Z] int<lower=0> t;     // Time of acquisition for each individual
array[K, T_max] real<lower=0> D; // Scaled durations
array[K, T_max] matrix[Z, Z] {paste0('A_', network_names, collapse = ', ')}; // Network matrices
array[K] matrix[T_max, Z] C;   // Knowledge state slash cue matrix
{ILV_declaration}
int<lower=0> N_veff;
array[K, T_max] int<lower=0> D_int; // integer durations
}}
")
# Parameters block
parameters_block <- glue::glue("
parameters {{
real log_lambda_0_mean;  // Log baseline learning rate
real log_s_mean;         // Overall social transmission rate
{w_param}
{ILVi_param}
{ILVs_param}
{ILVm_param}
{if (N_veff == 2) 'matrix[N_veff,Z] z_ID; vector<lower=0>[N_veff] sigma_ID; cholesky_factor_corr[N_veff] Rho_ID;' else ''}
}}
")
# Transformed parameters block
transformed_parameters_block <- glue::glue("
transformed parameters {{
{if (N_veff == 2) '
matrix[Z,N_veff] v_ID;
v_ID = (diag_pre_multiply(sigma_ID, Rho_ID) * z_ID)\\';
vector<lower=0>[Z] lambda_0 = 1 / exp(log_lambda_0_mean + v_ID[,1]);
vector<lower=0>[Z] s = exp(log_s_mean + v_ID[,2]);
' else '
real<lower=0> lambda_0 = 1 / exp(log_lambda_0_mean);
real<lower=0> s = exp(log_s_mean);
'}
}}
")
# Model block
model_block <- glue::glue("
model {{
log_lambda_0_mean ~ normal(6, 2);
log_s_mean ~ normal(1, 2);
{w_prior}
{ILVi_prior}
{ILVs_prior}
{ILVm_prior}
for (trial in 1:K) {{
for (n in 1:N[trial]) {{
int id = ind_id[trial, n];
int learn_time = t[trial, id];
if (learn_time > 0) {{
for (time_step in 1:learn_time) {{
real ind_term = {ILVi_variable_effects};
real soc_term = {if (N_veff == 2) 's[id]' else 's'} * ({network_term}) {ILVs_variable_effects};
real lambda = {ILVm_variable_effects} {if (N_veff == 2) 'lambda_0[id]' else 'lambda_0'} * (ind_term + soc_term) * D[trial, time_step];
target += -lambda;
if (time_step == learn_time) {{
target += log({ILVm_variable_effects} {if (N_veff == 2) 'lambda_0[id]' else 'lambda_0'} * (ind_term + soc_term));
}}
}}
}}
}}
if (N_c[trial] > 0) {{
for (c in 1:N_c[trial]) {{
int id = ind_id[trial, N[trial] + c];
for (time_step in 1:T[trial]) {{
real ind_term = {ILVi_variable_effects};
real soc_term = {if (N_veff == 2) 's[id]' else 's'} * ({network_term}) {ILVs_variable_effects};
real lambda = {ILVm_variable_effects} {if (N_veff == 2) 'lambda_0[id]' else 'lambda_0'} * (ind_term + soc_term) * D[trial, time_step];
target += -lambda;
}}
}}
}}
}}
}}
")
generated_quantities_block <- glue::glue("
generated quantities {{
matrix[K, Q] log_lik_matrix = rep_matrix(0.0, K, Q);           // LL for each observation
for (trial in 1:K) {{
for (n in 1:N[trial]) {{
int id = ind_id[trial, n];
int learn_time = t[trial, id];
if (learn_time > 0){{
real cum_hazard = 0; //set val before adding
for (time_step in 1:T[trial]) {{
real ind_term = {ILVi_variable_effects};
real soc_term = {if (N_veff == 2) 's[id]' else 's'} * ({network_term}) {ILVs_variable_effects};
real lambda = {ILVm_variable_effects} {if (N_veff == 2) 'lambda_0[id]' else 'lambda_0'} * (ind_term + soc_term) * D[trial, time_step];
cum_hazard += lambda; // accumulate hazard
//if it learn_time, record the ll
if (time_step == learn_time){{
log_lik_matrix[trial, n] = log({ILVm_variable_effects} {if (N_veff == 2) 'lambda_0[id]' else 'lambda_0'} * (ind_term + soc_term)) - cum_hazard;
}}
}}
}}
}}
// Contributions of censored individuals
if (N_c[trial] > 0) {{
for (c in 1:N_c[trial]) {{
int id = ind_id[trial, N[trial] + c];
int censor_time = T[trial]; // Censoring time (end of observation)
// compute cumulative hazard up to the censoring time
real cum_hazard = 0;
for (time_step in 1:censor_time) {{
real ind_term = {ILVi_variable_effects};
real soc_term = {if (N_veff == 2) 's[id]' else 's'} * ({network_term}) {ILVs_variable_effects};
real lambda = {ILVm_variable_effects} {if (N_veff == 2) 'lambda_0[id]' else 'lambda_0'} * (ind_term + soc_term) * D[trial, time_step];
cum_hazard += lambda; // accumulate hazard
}}
// Compute per-individual log likelihood
log_lik_matrix[trial, N[trial] + c] = -cum_hazard;
}}
}}
}}
{if (est_acqTime==TRUE) '
matrix[K, Q] acquisition_time;         // simulated acquisition times
for (trial in 1:K) {
for (n in 1:Q) { //have to loop through bc stan
acquisition_time[trial, n] = time_max[trial];
}
for (n in 1:Q) {
int id = ind_id[trial, n];
int learn_time = t[trial, id];
if (learn_time > 0){
real cum_hazard = 0; //set val before adding
int global_time = 1;
for (time_step in 1:T[trial]) {
for (micro_time in 1:D_int[trial, time_step]){
real ind_term = 1;
real soc_term = s * (sum(A_assoc[trial, time_step][id, ] .* C[trial][time_step, ]));
real lambda =  lambda_0 * (ind_term + soc_term);
real prob = 1-exp(-lambda);
if (bernoulli_rng(prob) && acquisition_time[trial, n]>=time_max[trial]) {
acquisition_time[trial, n] = global_time;
}
global_time += 1;
}
}
}
}
}' else ''}
// Flatten log_lik_matrix into log_lik
array[K * Q] real log_lik;
int idx = 1;
for (trial in 1:K) {{
for (n in 1:Q) {{
log_lik[idx] = log_lik_matrix[trial, n];
idx += 1;
}}
}}
}}
")
# combine all blocks
stan_model <- glue::glue("{data_block}
{parameters_block}
{transformed_parameters_block}
{model_block}
{if (gq==T) generated_quantities_block else ''}")
return(stan_model)
}
#generate STAN model from input data
model_obj = generate_STb_model(data_list_user, gq=TRUE, est_acqTime = T)
# suggest writing to file for debugging
write(model_obj, file = "../data/model_from_simulate_data.stan")
# fit model
fit = fit_STb(data_list_user, "../data/model_from_simulate_data.stan", chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99))
# check estimates
STb_summary(fit, digits=4)
acqdata = extract_acqTime(fit, data_list_user)
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_abline(slope = 1, intercept = 0,             # Line y = x
color = "red", linetype = "dotted", size = 1) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
# test import_NBDA_STb
data_list_nbda = import_NBDA_STb(d, network_names = c("assoc"))
model_obj = generate_STb_model(data_list_nbda)
#this should give the same results as fit above
fit = fit_STb(data_list_nbda, model_obj, chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99) )
model_obj = generate_STb_model(data_list_nbda, gq=T, est_acqTime = T)
#this should give the same results as fit above
fit = fit_STb(data_list_nbda, model_obj, chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99) )
STb_summary(fit)
acqdata = extract_acqTime(fit, data_list_user)
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_abline(slope = 1, intercept = 0,             # Line y = x
color = "red", linetype = "dotted", size = 1) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
# fit model
fit = fit_STb(data_list_user, "../data/model_from_simulate_data.stan", chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99))
# check estimates
STb_summary(fit, digits=4)
acqdata = extract_acqTime(fit, data_list_user)
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_abline(slope = 1, intercept = 0,             # Line y = x
color = "red", linetype = "dotted", size = 1) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_segment(
aes(x = observed_time, xend = observed_time, y = mean_time, yend = observed_time), # connect predicted to slope line
color = "red",
alpha = 0.2
) +
geom_point(alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed") +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
#generate STAN model from input data
model_obj = generate_STb_model(data_list_user, gq=T, est_acqTime = T)
# suggest writing to file for debugging
write(model_obj, file = "../data/model_from_simulate_data.stan")
# fit model
fit = fit_STb(data_list_user, "../data/model_from_simulate_data.stan", chains = 5, cores = 5, iter=2000, control = list(adapt_delta=0.99))
# check estimates
STb_summary(fit, digits=4)
#get data for estimated times
acqdata = extract_acqTime(fit, data_list_user)
#plot estimated times versus observed times w/ HPD
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_abline(slope = 1, intercept = 0,             # Line y = x
color = "red", linetype = "dotted", size = 1) +
geom_pointrange(aes(ymin = lower_hpd, ymax = upper_hpd), size=.8) +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with 95% HPD Intervals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
#plot estimated times versus observed times w/ residuals
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_segment(
aes(x = observed_time, xend = observed_time, y = mean_time, yend = observed_time), # connect predicted to slope line
color = "red",
alpha = 0.2
) +
geom_point(alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed") +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with residuals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
#plot estimated times versus observed times w/ residuals
ggplot(acqdata, aes(x = observed_time, y = mean_time)) +
geom_segment(
aes(x = observed_time, xend = observed_time, y = mean_time, yend = observed_time), # connect predicted to slope line
color = "red",
alpha = 0.2
) +
geom_point(alpha = 0.6, size=2) +
geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed") +
facet_wrap(~trial, scales = "free_x") +
labs(
title = "Estimated acquisition time with residuals",
x = "Observed time",
y = "Estimated time"
) +
theme_minimal()
ggsave("../data/estimates_residuals.png", width=8, height=8, units="cm", scale=1.5)
